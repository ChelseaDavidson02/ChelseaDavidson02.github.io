In early May 2023 what was claimed to be an internal memo from an unnamed Google researcher was leaked and widely shared and discussed. It opens with the title - "We have no moat, and neither does OpenAI", and proposes that the strongest player in the current AI arms race is not Google, nor OpenAI, but the distributed army of open source researchers. There are a number of reasons that the memo discusses, but for this blog I want to focus on an aspect that is prominent in the Fast-AI course -- Fine Tuning.

Fine-tuning is a technique that allows us to train a model for a specific task using a pre-trained model that has learned general features from a large dataset. For example, suppose we want to create a model that can classify different types of flowers. Instead of training a model from scratch using thousands of images of flowers, we can use a pre-trained model that has been trained on a large dataset of natural images, such as ImageNet. This pre-trained model already knows how to recognise basic shapes, colours, textures, and patterns that are common in natural images. We can then fine-tune this model by replacing the last layer with a new layer that has the number of classes we want (e.g., roses, tulips, sunflowers, etc.) and training it on a smaller dataset of flower images. This way, the model will learn to adjust its weights and biases to fit the new task, while keeping most of the features learned from the previous task.

This process can leverage the knowledge and experience of the pre-trained model and adapt it to a specific problem, without having to train from scratch or use a lot of data. The "No Moat" memo looks at LoRA - the Low-Rank Adaption of Large Language models, since it is focused on the fine-tuning of large language models. But the general conclusions apply to any fine tuning approach. 

Training large models is hard and expensive -- it requires large data sets and costly computational resources. Retraining models from scratch every time an improvement is made is inefficient, as it throws away any pretraining or other improvements that have been made. In contrast fine tuning allows for iterative improvement, usually with rapid and cheap iterations. With many iterations this process will usually develop better models than even a much larger model trained from scratch.

There is another advantage to fine-tuning mentioned in the "No Moat" memo -- data quality scales better than data size. Fine tuning can be done with a small training set that has been carefully selected to focus on the desired training features. In many cases these training sets can be generated from curated outputs from synthetic generators, even from proprietary models. 

Applying a fine-tuning technique to a FastAI image model is very simple. Once the libraries have been imported and the data loaded, the following steps are necessary.

1. Create a vision learner object using the cnn_learner function and specify the pre-trained model architecture, such as resnet18 or vgg16.
2. Train the model using the fit_one_cycle method and optionally use the lr_find and plot_lr methods to find the optimal learning rate.
3. Evaluate the model using the show_results and confusion_matrix methods and optionally use the fine_tune method to further improve the model.


Fine-tuning democratises the training of new applications of AI, because it lowers the barriers of entry and reduces the costs and resources needed to create high-quality models. Anyone with a basic understanding of AI and access to a pre-trained model can fine-tune it for their own purpose. For vision models this could be for face recognition, object detection, image segmentation, or any other vision task. For generators this could be for creating images of a very specific style. For language models this could be to generate responses for specific content areas, such as legal advice, medical diagnosis or advertising copy.
At the wider level, fine-tuning enables faster experimentation and innovation which, combined with the communities already developed in open source and online communities (such as Reddit) may limit the dominance of large companies in the future development of AI.
